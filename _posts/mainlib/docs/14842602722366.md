# TITLE标题
SVR Collaborative Filtering Algorithm Combining with KNN 

## ABSTRACT摘要
Recommender systems have been very important components to prevent people from dwelling in the overwhelming information. The capability of a recommender system is establishing contact between the users and the items which represent the mapping of interests and preferences.  Collaborative filtering assumes that users with similar interests in the past will mostly share the similar interests in the future, and will recommend to each user a descending sequences of might be interesting items without already bought or confirmed like items.
In this paper we analyze the difference between item-based recommendation algorithms and SVR-based collaborative filtering algorithms, and we found item-based method performs much better while the data is significantly sparse, and SVM-based method performs better while the data is dense. On this premise we propose a method that can combine the advantages of these two methods by firstly predict a small part of ratings using Support Vector Regression method and then predict the rest of ratings using the item-based algorithm, which can solve the problem of data sparsity to the certain extend. Finally, we experimentally evaluate our results compared with the benchmark and prove our method's advantages and the future improvement points. 
## aKeywords
Support Vector Regression
Item-Based Recommendation
Collaborative Filtering
Data Sparsity
personal pereference 
## 1.INTRODUCTION 
 For nearly decades of time, the data for recommend systems to work are usually based on users and items, which are typically displayed as U-I matrices. There are basically two major benchmarks to realize collaborative filtering so to explore the relationship between users and items.One way is memory-based method including user-based CF and item-based CF. This method often calculates the similarity function between users or items to decide the particular users' predicting rates for unknown or unpaid items. Another way of collaborative filtering is the model-based method which directly construct a map between input rates and the predicting rates. The previous research have shown even a little progress in the predicting process, the recommend work will get a remarkable advance.
  However, both CF algorithms suffers from the data sparsity because the data attribute that most datasets lacks more than 90% of the datas. It means that even we have the best prediction algorithms, we can't get a convincing result because of the principle of statistics.
  In this paper we put forward a recommend algorithm that combines the KNN item-based CF and the SVR model-based CF to solve the problem of data sparsity. At the first step, we record the majority part of rated items and users and use SVR model to predict a pre-filled U-I matrix, and then at the second step, we use the item-based algorithm to predict the pre-filled U-I matrix. In this way we can firstly get part of comparable accurate data rather than empty data to deal with the sparse data.
  The rest of the paper is organized as follows. Section 2 introduces the notation. Section 3 presents the related work. Section 4 presents the proposed model. Section 5 presents the evaluation methodology and the performance of the method. Section 6 presents the future work. Finally, Section 7 provides some method conclutions.
## 2.NOTATION
The number of users is denoted by n and the number of items is denoted by m. Matrix R is used to represent the user-item implicit matrix of size n * m. It shows which items the users have purchased/viewed/rated. Symbols u and i are used to denote individual users and items, respectively. We will use the term rating to refer to the non-zero entries of R. We also refer to the items that the user has purchased/viewed/rated as rated items and to the rest as unrated items. The set of items that the user u has rated will be denoted by Ru. And we use K to denote the number of neighborhood that we choose to predict missing rating values in the Item-Based algorithm.
## 3.RELATED WORK
### 3.2 ITEM-BASED Recommendation Methods
In item-based collaborative filtering, the unpredicted ratings' estimation depends on the active user’s mean rate xa and ratings of its similar users (we also refer to them as ua’s neighbors). Based on the set of ratings by uj, we can define its mean rating as
Usually a closer neighbor uj to ua, should contribute a larger weight to the estimation. The weight can be measured by the similarity between two users. A widespread measure is the Cosine similarity which was introduced in [15]. The weight that uj contributes to ua is defined as 

### 3.2 SVR Models for Recommendation
 Model-based approaches have been studied to overcome the sparsity problem by learning a model for predicting ratings of unobserved items. 
 The SVR models treat collaborative filtering as a regression problem using support Vector Machine. 
One way is to treat every item as a separate classification or regression problem. Given an item n, one can build a classifier to predict which class the active user belongs to. Every user uj is represented as a vector in the feature space by using uj’s ratings on items other than n. A more common way to predict the missing rates is to treat every user as a separate classification or regression problem [4]. One can build a model for the active user ua by using items as training instances. 
## 4.PROPOSED APPROACH
### 4.1 Motivation（方法动机，原理）
Both the Item-based collaborative filtering and the SVR model-based algorithm have its own advantages and particular restrictions, so we represent a method that can combine the advantages of both algorithms and prevent  the sparsity problem. An item-based method CF can predict rating fast and has the good scalability, however using one similarity function to evaluate the whole dataset might not pretty precise especially when the datasets are extremely sparse. When it comes to SVR model-based method, we can use the precise power of support vector machine to classify data or do regression to predict the missing value, but the time consuming training process and the probability of over-fitting makes this method lack of flexibility. 
    After observing the data, we found that the data was composed by comparably dense part and sparse part. The previous prediction method often pre-fill the missing value as average rating of an item or the average rating of the user to predict the U-I matrix. So we want to at the first step predict the missing value of the dense part using SVR model, and at the second step, we re-predict the missing value of the sparse part using item-based model added with the firstly predicted data as input data, the simplified process is denoted in the figure 1.
     
### 4.2 Overview of Model（介绍模型和计算公式）


To be specific, training instance n isrepresented as a feature vector xn in which elements are ratingsprovided by other users. Without loss of generality, we consider the first user u1 as the active user and u1 has rated the first l items, that is, I1={1,...,l}. Then, the feature vector of itemn,1≤n≤l,i s x =(x ,x ,...,x )T and its class label y is rating n 2n3n Mn nx1n . We need to predict labels for all other feature vectorsxn,l +1≤ n ≤ N . 

Assign gu = 0.5, to every user u.Compute the initial clustering of users with CLUTO [1]. 
while number of users who switched clusters > 1% of the total number of users doEstimate S and Spu, 8pu 2 {1,...,k} with Equa- tion 4.for all user u dofor all cluster pu doCompute gu for cluster pu with Equation 5. Compute the training error.end forAssign user u to the cluster pu that has the smallest training error and update gu to the corresponding one for cluster pu.end for 
end while
### 4.3 Estimating the SVR Combines with KNN model（方法分析）

## 5.EXPERIMENTAL EVALUATION（实验结果）
### 5.1 Datasets
We evaluated the results of our method on different datasets, whose attributes are shown in Table 1.The MovieLens is the MovieLens 100k dataset [12], which represents movie ratings ranges from 1 to 5 as discrete integers. The jester dataset [10] is an online joke recommender system with ratings ranges from -10 to 10 as continuous real numbers. The EachMovie dataset is a movie rating dataset with ratings ranges from 0 to 1 as discrete real numbers. The BookCrossing dataset is the book integer ratings ranges from 0 to 10.
### 5.2 Evaluation Methodology（评价方法：mae／准确率）
We use five-fold cross-validation to evaluate the performance of the presented algorithm. We measure the performance by computing the predicted error of different methods by measuring the MAE and NMAE values.
### 5.3 Experimental Results
### 5.4 Performance against Traditional Approaches
item-based
svr
svr with item-based
The comparison of our presented method and the traditional item-based algorithms and SVR algorithm are shown in Table 2.  In conclusion, we can observe that our presented algorithm performs better when the sparsity value is extremely high. However when the data sparsity is not that high, for example the Jester data, the traditional algorithm is still good to predict missing values.
Another agility problem we encountered is that when facing the different data, we should choose different mount of firstly calculating data to do the SVR-model prediction because of different attributes result in different vector dimension. Because the SVR-model has the possibility of overfit, so we should properly choose the number of items as vector number and the user number as data quantity. 
The other advantage of our proposed method is that because the introducing of SVR-model, we make it better to utilize the tag information and timing information, and the other data attributes as vectors for Support Vector Machine to do regression works. In this way we needn't analyze the semantics of the attributes any more and just treat them as special vectors in the training process. 

### 6 Future Works（提出更好的方式）

SVR models with time and tags and 0-1
In order to make our algorithm better we need to rather than manually select the firstly calculated subset,

## 7.CONCLUSION
In this paper, we presented a method to improve the traditional KNN item-based recommendation algorithm, by dividing the prediction into two steps of predicting the dense part and the sparse part of data, and combining the precise prediction of SVR model-based CF and the scalability, time-saving prediction of the item-based algorithms. The newly presented method enrich the data in a reasonable way to solve the data sparsity problem, even though the pre-predicted data from SVR model-based method are not a hundred percent precise. The experiment results shows that the pre-prediction of the data to enrich the sparse information are mostly better than lacking information especially when the data is extremely sparse as more than 90% lack of imformation. However the presented method is too agility to decide what part of data should be called dense and what part should be called sparse, 

## 8.REFERENCES



